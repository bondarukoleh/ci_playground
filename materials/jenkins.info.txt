Jenkins is an open source continuous integration CI and continuous delivery tool written in Java.
It's an automation server used to build and deliver SW projects.
Was forked from another a-like server Hudson, after dispute or fight with Oracle.
It's cool to pack app in docker since it is isolated environment, and you can be more sure that your app works.
Major feature in Jenkins - plugins.

Jenkins is open source and well known but there are alternatives:
  - Self-hosted: Drone CI, TeamCity (by JetBrains)
  - Hosted (SaaS): Wercker, CircleCI, CodeShip, SemaphoreCI, Amazone AWS CI/CI tools.

Continuous Integration - is the practice of merging all developer working copies to a shared mainline several
times a day. Continuous Delivery - is the approach in which teams produce SW in short cycles, ensures that.
SW can be released in any moment. In practice CI/CD says that we will verify and publish SW by triggering
automated builds and test.

All developers push their changes to VCS where code tested at least once a day.
CI/CD with SDLC (SW development life cycle)
New Feature (by dev) ->
 Push (be dev) ->
  Build (by Jenkins) ->
   Test (Unit, Integration, Regression, Acceptance, etc) (by Jenkins) ->
    Release (Package SW, to tar, zip, jar, docker) (by Jenkins) ->
     :optional Distribute(to private storage/docker registry) ->
      Deploy to production(by Jenkins).

To install Jenkins with docker:
mkdir -p /var/jenkins_home
chown -R 1000:1000 /var/jenkins_home/
docker run -p 8080:8080 -p 50000:50000 -v /var/jenkins_home:/var/jenkins_home -d --name jenkins jenkins/jenkins:lts

We can make a jenkins with docker client, so jenkins container can run docker commands.

It's easy to setup Jenkins via UI. But there are several disadvantages of this approach:
- No audit trail, you'll never know who make a change, that break something.
- No history of changes, you don't know what was changed, that break something.
- No ability to easy backup or restore Jenkins setup.
- Usually developers don't have rights to change Jenkins setup, admins have, it takes time.

Many of those troubles will be solved if we will store Jenkins setup in Jenkins DSL, in VCS.

Jenkins Jobs
Job DSL - Jenkins plugin that allows to define jobs in programmatic way. It use Groovy based language
 Groovy - is like scripting language for Java platform, runs in JVM.
So we create a job in Jenkins that will be creating jobs with DSL.
We can download DSL scripts from repositories from Process Job DSLs Build block - but first
  we need to approve using them. In Manage -> In-process Script Approval -> Approve

If node is node executable on jenkins, since all ls or copy or npm commands is looked in $PATH
we need to add npm to $PATH.
Easy way to find where npm is installed.
jenkins@$>npm start
bash: npm: command not found
jenkins@$>find ~ -name 'npm'
jenkins@$>export PATH=$PATH:/var/jenkins_home/tools/jenkins.plugins.nodejs.tools.NodeJSInstallation/nodejs/bin

As we can see from registryCredentials('dockerhub') in DSL script - there are id from credentials to
  dockerhub, to push builded docker. You can add it in Credentials (left menu, not in manage) ->
    Add -> and set ID - same as in script 'dockerhub'

Jenkins Pipelines
Allow you to write Jenkins build steps in code.
Build steps allow you to write: build (compile), test, deploy in code, mean you can put setup
for all of these steps - in VCS.
It's a way to automate SDLC.
Pipelines is a type of Jobs, we can do a huge "free style" Job and do same as in pipeline,
difference is in implementation in Jenkins.
Cool feature - is "Organization folder" - pipeline job that have separately diff repositories,
and you can logically divide build steps.

Pipeline can be created via UI or Job DSL (Jenkins DSL or Groovy script)
Jenkins DSL will be interpreted by Groovy under the hood anyway.

Pay attention, when you did a job groovy script - you created a general project
that creates a job from provided job script. When you do a pipeline - it doesn't
create some extra entities like another pipeline or job - it is a pipeline that
would do the steps described in script. But still you've created pipeline manually,
which I think could be done in code.

Benefits of keeping jenkins pipeline groovy script within the app code is huge.
You don't need the taskFile.sh or start-tests.sh in your library, you don't need
to change anything, in your created pipeline on Jenkins side - changes in app code
can be supported in jenkins file that lies here with the code, incredible.

Docker pipeline let's you not only build but run any container within pipeline.
For example you want to pack app inside the container, but only production code,
and still want to test and develop it in isolated environment mean use containers.
So we can build a large container with tests and all stuff, run it, test it,
and then build a container only with tested prod code and push it.

Also we can add any container with some stuff, during Pipeline, use it, and remove
after tests are done e.g. container with test mocked DB, run tests on it, and
remove it after testing stage. Also it works with multiple builds at the same time,
e.g. you are building a few versions of app - and you'll get a clean new DB container
for each of those which is pretty cool.

It's an alternative way to run for instance node commands - you remember that you need
to setup "Build Environment" for Jenkins and put a NodeJS installation path in it?
It's much better way to have ability to get NodeJS environment dynamically with
different versions of it.

**Note about inside, run, withRun:
Image.run([args, command])
Uses docker run to run the image, and returns a Container which you could stop later.
Additional args may be added, such as '-p 8080:8080 --memory-swap=-1'. Optional command
is equivalent to Docker command specified after the image. Records a run fingerprint in
the build.

Image.withRun[(args[, command])] {…}
Like run but stops the container as soon as its body exits, so you do not need a try-finally
block.

Image.inside[(args)] {…}
Like withRun this starts a container for the duration of the body, but all external commands
(sh) launched by the body run inside the container rather than on the host. These commands
run in the same working directory (normally a Jenkins agent workspace), which means that
the Docker server must be on localhost.

Emailing
We can send an email with build result.
The earlier dev gets the fail the better, solution is more or less fresh in his head,
and he can fix it more quickly.
Build should run on each commit in master branch.
VSC can be pulled by Jenkins, means Jenkins asking e.g. each 5 minutes - is there any
change? This functionality is in Jenkins.

Or Jenkins could be pushed from VSC - there was some change - make a build. There are
a few plugins github, bitbucket to configure this functionality.


